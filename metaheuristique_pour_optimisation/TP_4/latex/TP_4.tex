\documentclass[a4paper]{article}
%\documentclass[8pt]{report}
%%%%%%%% CREATE DOCUMENT STRUCTURE %%%%%%%%
%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}

%\usepackage{subfig}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=2cm,right=2cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
%\usepackage{caption}
\usepackage[justification=centering]{caption}
\usepackage{subcaption}
\usepackage{sectsty}
\usepackage{float}
\usepackage{titling} 
\usepackage{blindtext}
\usepackage[square,sort,comma,numbers]{natbib}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{xcolor}
\usepackage{fancyhdr}
\usepackage{lipsum}

%% definitions 
\definecolor{darkgreen}{rgb}{0.0, 0.4, 0.0}

%% Define your personal info here %%%%%%%%%%%%%%%%%%%%%%%
\newcommand\TPid{4}
\newcommand\TPname{Ant System for Travelling Salesman Problem}
\newcommand\Firstname{Joao Filipe}
\newcommand\Familyname{Costa da Quinta}
\newcommand\Email{Joao.Costa@etu.unige.ch}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%% Page header %%%%%%
\pagestyle{fancy}
\fancyhf{}
\rhead{TP \TPid: \TPname}
\lhead{\Firstname \Familyname}
\rfoot{Page \thepage}


%%%%%%%% DOCUMENT %%%%%%%%
\begin{document}

%%%% Title Page
\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} 							% horizontal line and its thickness

\center 
 
% University
\textsc{\LARGE Université de Genève}\\[1cm]

% Document info
\textsc{\Large Metaheuristics for optimization}\\[0.2cm]									% Course Code
\HRule \\[0.8cm]
{ \huge \bfseries TP \TPid : \TPname}\\[0.7cm]								% Assignment
\HRule \\[2cm]
\large
\emph{Author:} \Firstname \; \Familyname\\[0.5cm]		
\emph{E-mail:} {\color{blue}\Email}\\[7cm]		
% Author info
% Author info
{\large \today}\\[2cm]
\includegraphics[width=0.4\textwidth]{images/unige_csd.png}\\[1cm] 	% University logo
\vfill 
\end{titlepage}


% ============================================
% ----------------------------------
\newpage
\section{Introduction}
During this TP we will be working on the Travelling Salesman Problem (TSP), this is a well known problem. It consists of a Salesman that is given $n$ cities/places that he has to visit, we also assume that from any city, there is a path to visit any other city with a given distance. The goal is to find the best (shortest) path such that every city is visited exactly once, this path is also called the Hamiltonian cycle of minimal length on a fully connected graph.

\section{Ant System}
Ant System (AS) is an algorithm that is designed to copy the effect of nature itself, this is what we did during the last TP as well. This time we will copy the behaviour of a group of animals, a group of ants to be more specific, hence the name of the algorithm.\\\\ Ants are not extraordinarily smart individuals, however, a group of ants is capable of incredible things. More specifically, they are capable, as a group, of finding the shortest path between their nest and a food source. Many scientific studies were done to try and understand how they were capable of such things, once we found out, we simply tried to implement the same logic into an algorithm.\\\\
What happens in nature, is that ants will randomly take a path to try and find food, at every interval of time, let's say each second, they leave behind pheromones. When new ants are coming to try and find food, they won't choose a path completely at random, they will more likely choose a path that has more pheromone, as this presence of pheromone indicates that more ants took this path than any other path.
\section{Ant System for TSP}
Let's try and apply this algorithm to TSP problem, the goal is to start the ants in one given city, and define a path as complete, if they went through each city once, and ended up at the beginning, in this analogy, the food source is in the same place as the nest. The goal is to find the shortest path that respects the conditions.\\\\ If there are $n$ cities we want to visit, a state will be a representation of which the Travelling Salesman (the Ant) visits in order. $S = [1,2,3,1]$ this state means we start at city 1, go to city 2, then 3, and finally we comeback to city 1. (We want to finish were we started). In this example n = 3, but the length of our state is 4 = n + 1. The start and end are predetermined, which means the search space is $(n-1)!$.\\\\ The total distance for a given path, is as follows : $\sum_{i = 1}^{n} D(s_{i}, s_{i+1})$ where $D(a,b)$ is the distance between city $a$ and $b$, the energy of a state will be represented by the total distance. A neighbour of a given state, is a simple city permutation in the path.\\\\
Let's see how we implement these natural mechanisms in our algorithm.\\\\
In our algorithm, a given number of ants, will try and find the best path individually, each ant attempts to find the path a certain number of times, and we goal, is that in the last iteration one of the ants finds the best path possible. The pheromone will be left at the end of an iteration, and for the next iteration the ants can make an informed decision on which path to take, based on the amount of pheromone. However, we must keep in mind that the first iteration the path is chosen at random.\\\\
\begin{itemize}
\item[(1)] Define set $J$, this set contains a list of the cities that are unvisited by a given ant. When we add a city to our path, we must delete it from $J$, which means that when $J$ is empty, the ant has found a path that respects the conditions.
\item[(2)] First task is to compute the matrix $D$ where $D_{ij}$ is the distance between cities $i$ and $j$.
\item[(3)] Compute $\eta$ where $\eta_{ij} = \frac{1}{D_{ij}}$.
\item[(4)] We create a function that returns $\tau_{ij}(t)$, this is the intensity of the path between $i$ and $j$ at iteration $t$. This intensity is the amount of pheromones.
\item[(5)] Implement a function that updates the pheromones $\tau_{ij}$. The pheromones are updated by following the next equation:\\
$$\tau_{ij}(t+1) = (1 - \rho) * \tau_{ij}(t) + \sum_{k=1}^{\#ants = m} \Delta \tau_{ij}^k(t)$$
where $\rho$ is the evaporation rate of the pheromones between each iteration, and $\Delta \tau_{ij}^k(t)$ is defined by the following equation:\\
$$\Delta \tau_{ij}^k(t) = \begin{cases} \frac{Q}{L^k(t)}$ if ant $k$ used edge $(i,j)$ in its path $\\ 0$ otherwise$ \end{cases}$$
where $Q$ is a predefined constant and $L^{k}$ is the length of the path taken by the ant. This means that a longer path will have a smaller $\frac{Q}{L^k(t)}$, which results in less pheromone for the next iterations.
\item[(6)] Finally we have to implement a function that chooses which city we visit next in our path, this is done by following the next formula:
\end{itemize}

\newpage
\section{Results}
We will run the algorithm in a unit circle of n cities, all at the same distance from the center, so the best solution is a path in shape of a circle, and then we will run the algorithm for 2 sets of cities that are given. Finally we will generate sets of larger cities, and see what happens.\\\\
For benchmark, we will use a simple greedy algorithm, this algorithm will go from city to city, always choosing the next village as the closest one that it hasn't visited yet. This algorithm is obviously deterministic. 
\begin{figure}[H]
\center
\includegraphics[width=1\textwidth]{images/algorithm_greedy.PNG}
\caption{Path found by greedy algorithm. From left to right we have : unit circle, cities.dat, cities2.dat}
\end{figure}
We can see that the algorithm only works for a perfect case scenario, and as we increase difficulty, it begins to make a mess of its path
\begin{figure}[H]
\center
\includegraphics[width=1\textwidth]{images/algorithm_sa_circle.PNG}
\caption{Initial path and found solution found by SA algorithm for unit circle. The energy mean for 10 runs was : 6.69}
\end{figure}
\begin{figure}[H]
\center
\includegraphics[width=1\textwidth]{images/algorithm_sa_cities.PNG}
\caption{Initial path and found solution found by SA algorithm for cities.dat. The energy mean for 10 runs was : 28.68}
\end{figure}
\begin{figure}[H]
\center
\includegraphics[width=1\textwidth]{images/algorithm_sa_cities2.PNG}
\caption{Initial path and found solution found by SA algorithm for cities2.dat. The energy mean for 10 runs was :}
\end{figure}

We see that for every case the SA algorithm performed better than the greedy. However we also notice that the mean Energy result for SA algorithm wasn't as good as the best case scenario. This is not the fault of the algorithm itself, but because of the definition of neighbourhood that we use. As we saw in class, there was another possible permutation to find neighbours, the $2-opt$, this permutation would have given better mean results for every use case.\\\\
To test our code further we had to generate a random problem of a larger size $n$.

\begin{center}
Random problem generator for $n = \{50, 100, 150\}$\\
\begin{tabular}{|c|c|c|c|}
\hline
        &  greedy algorithm &  SA best result &  SA mean result \\ \hline
 n = 50  &  136.10           &  115.85        &  123.65        \\ \hline
 n = 100 &  205.24           &  188.22    &  200.66         \\ \hline
 n = 150 &  243.78          &     240.92           &  259.68         \\ \hline
\end{tabular}
\end{center}
In every $n$ greedy algorithm was outperformed by SA, it must be noted that SA had difficulties with $n = 150$, and it's mean result is actually worse than greedy algorithm, out of 10 executions, only one was better than greedy algorithm. We have to take into account that the 150 cities were all in a plane of 20 by 20, which means there wasn't actually many possibilities for the greedy algorithm to go wrong, my assumption is that in a larger plane greedy algorithm wouldn't be as accurate. This being said, I didn't rerun the simulation in a larger plane as it took way too long.\\\\
We do have to take into account the complexity of both algorithms, greedy has a time complexity of $O(2n)$, however SA algorithm has a much higher time complexity. If we look back at the flowchart of the algorithm, step (4) was iterated at least $n^{2}$ times, which means the complexity is at least $O(n^{2})$.\\\\
With all the results having been discussed, I must admit I was very impressed at how well the algorithm performed, and how it was capable to optimize the path while trying to emulate a real physical process found in nature.
\end{document}
